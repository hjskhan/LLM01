{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OpenAI Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key = os.environ['OPENAI_API_KEY'],temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The height of the Statue of Liberty from the base to the tip of the torch is 305 feet and 1 inch (93 meters). However, including the pedestal and foundation, the total height of the statue is 305 feet and 6 inches (93.6 meters).\n"
     ]
    }
   ],
   "source": [
    "text = 'What is height of Statue of Liberty'\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Huggug Face Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface api key\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Documents\\GitHub\\LLM01\\llmvenv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_hugging_face = HuggingFaceHub(repo_id='google/flan-t5-large', model_kwargs={'temperature':0.6, 'max_length':75})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 m\n"
     ]
    }
   ],
   "source": [
    "text = 'What is height of Burj Khalifa'\n",
    "print(llm_hugging_face.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The height of the Burj Khalifa is 828 meters (2,717 feet).\n"
     ]
    }
   ],
   "source": [
    "text = 'what is the height of the Burj Khalifa'\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Chain and Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is height of Burj Khalifa'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "promp_template = PromptTemplate(input_variables=['building'],template = 'What is height of {building}')\n",
    "promp_template.format(building='Burj Khalifa')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm_hugging_face, prompt=promp_template)\n",
    "print(chain.run('Burj Khalifa'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Multiple Chain using Simple Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is a right-handed batsman and a right-handed batsman.\n"
     ]
    }
   ],
   "source": [
    "temp1 = PromptTemplate(input_variables=['country'], template='What is the most popular sports in {country}')\n",
    "chain1 = LLMChain(llm=llm_hugging_face, prompt=temp1)\n",
    "temp2 = PromptTemplate(input_variables=['game'], template='Tell me about his personal information of the most famous player of the{game}')\n",
    "chain2 = LLMChain(llm=llm_hugging_face, prompt=temp2)\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[chain1, chain2])\n",
    "print(chain.run('England'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = PromptTemplate(input_variables=['country'],\n",
    "                        template='Which is the most famous sports in {country}')\n",
    "chain1 = LLMChain(llm=llm_hugging_face, prompt=temp1, output_key='sports')\n",
    "\n",
    "temp2 = PromptTemplate(input_variables=['sports'],\n",
    "                        template='Who is the most famous player in {sports}')\n",
    "chain2 = LLMChain(llm=llm_hugging_face, prompt=temp1, output_key='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'England', 'sports': 'cricket', 'player': 'cricket'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(chains=[chain1, chain2], \n",
    "                        input_variables=['country'],\n",
    "                        output_variables=['sports', 'player'])\n",
    "\n",
    "print(chain({'country':'England'}))\n",
    "#Output quality depends on the LLM model chosen. Open Source models may not be as accurate as OpenAI models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat models with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "# defining llm model\n",
    "chatllm =  ChatOpenAI(openai_api_key = os.environ['OPENAI_API_KEY'], temperature= 0.6, model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The Bermuda Triangle, also known as the Devil's Triangle, is an area in the western part of the North Atlantic Ocean where several ships and aircraft have disappeared under mysterious circumstances. The boundaries of the triangle are often defined as being between Miami, Bermuda, and Puerto Rico.\\n\\nThe Bermuda Triangle gained its reputation for mysterious disappearances in the mid-20th century. Many stories and theories have been proposed to explain the phenomena, ranging from paranormal explanations to natural occurrences. Here are some of the most famous mysteries associated with the Bermuda Triangle:\\n\\n1. Flight 19: In December 1945, a group of five U.S. Navy TBM Avenger torpedo bombers vanished during a training exercise. The planes and their 14 crew members were never found, leading to speculation about possible explanations such as navigational errors or supernatural forces.\\n\\n2. USS Cyclops: In March 1918, the USS Cyclops, a U.S. Navy cargo ship, disappeared without a trace while traveling from Barbados to Baltimore. The ship's disappearance remains one of the biggest non-combat losses in U.S. naval history.\\n\\n3. Ellen Austin: In 1881, the schooner Ellen Austin reportedly found an abandoned ship in the Bermuda Triangle. The captain of the Ellen Austin decided to tow the ship to port, but it disappeared during a storm, leaving behind only mystery and unanswered questions.\\n\\n4. Disappearing Compasses: There have been reports of compasses malfunctioning or behaving erratically in the Bermuda Triangle. This has led to theories about the existence of electromagnetic anomalies or navigation-disrupting forces in the area.\\n\\n5. Atlantis Connection: Some theories suggest that the Bermuda Triangle is connected to the lost city of Atlantis. These theories propose that the mysterious disappearances are due to advanced technology or alien interference associated with the legendary civilization.\\n\\nDespite the popular fascination with the Bermuda Triangle, many experts argue that the number of disappearances in the area is not statistically significant and can be explained by natural causes such as extreme weather conditions, human error, or technical malfunctions. The U.S. Navy and Coast Guard do not recognize the Bermuda Triangle as an official danger zone.\\n\\nWhile the Bermuda Triangle continues to captivate the imagination of many, the exact nature of its mysteries remains unsolved. Theories and speculation persist, but conclusive evidence supporting supernatural or extraterrestrial explanations is lacking.\")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "    SystemMessage(content='you are a historian AI assistant'),\n",
    "    HumanMessage(content='Tell me about the mystries of bermuda triangle')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template + LLM + OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nervousness', ' Worry', ' Tension', ' Unease', ' Apprehension']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")\n",
    "    \n",
    "template=\"Your are a helpful assistant. When the use given any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])\n",
    "\n",
    "chain=chatprompt|chatllm|Commaseperatedoutput()\n",
    "\n",
    "chain.invoke({\"text\":\"Anxiety\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
